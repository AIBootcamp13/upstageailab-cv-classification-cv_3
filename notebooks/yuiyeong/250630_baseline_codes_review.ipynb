{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86372f1b965adb5",
   "metadata": {},
   "source": "# Notebook 기본 세팅"
  },
  {
   "cell_type": "code",
   "id": "3bbee03e090649db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:05.737382Z",
     "start_time": "2025-07-01T05:30:05.733741Z"
    }
   },
   "source": [
    "# Constant 선언\n",
    "\n",
    "# 프로젝트 루트 디렉토리를 식별하기 위한 마커 파일 이름\n",
    "ROOT_MARKER = \"pyproject.toml\"\n",
    "\n",
    "# 한글 표시를 위한 나눔바른고딕 폰트 파일 이름\n",
    "# matplotlib 의 font_manager 에 실제 폰트 파일의 위치를 넣어주어야 한다.\n",
    "KOREAN_FONT_FILE = \"NanumBarunGothic.ttf\"\n",
    "\n",
    "# matplotlib 에서는 font-family 의 이름으로 font 를 설정한다.\n",
    "# 그래서 font 파일 그 자체가 아니라, 그 파일의 family 이름을 적어준다.\n",
    "KOREAN_FONT_FAMILY = \"NanumBarunGothic\"\n",
    "\n",
    "# 참고\n",
    "# Font Family 와 Font File 의 차이는,\n",
    "# Font Family 는 비슷한 디자인 특성을 공유하는 글꼴 그룹을 의미한다.\n",
    "#\n",
    "# 예를 들어 '나눔바른고딕' 폰트 패밀리는 일반(Regular), 굵게(Bold), 기울임(Italic) 등 여러 스타일을 포함할 수 있다.\n",
    "# 반면, 폰트 파일(.ttf, .otf 등)은 이러한 폰트의 하나의 스타일이 저장된 실제 파일이다.\n",
    "#\n",
    "# 이 프로젝트에서는 폰트 용량을 줄이기 위해 일반(Regular) 인 NanumBarunGothic.ttf 만 사용한다."
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "93f2746669fe3b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:05.742415Z",
     "start_time": "2025-07-01T05:30:05.740018Z"
    }
   },
   "source": [
    "# 프로젝트 root 를 sys.path 에 추가해서 import 구문을 사용하기 쉽게\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    pyproject.toml 파일을 기준으로 루트 디렉토리를 찾는다.\n",
    "    :return: Path: 프로젝트 루트 디렉토리 경로\n",
    "    \"\"\"\n",
    "\n",
    "    current_path = Path().resolve()\n",
    "\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / ROOT_MARKER).exists():\n",
    "            return current_path\n",
    "\n",
    "        current_path = current_path.parent\n",
    "\n",
    "    raise FileNotFoundError(\"프로젝트 루트 디렉토리를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "ROOT_DIR = find_project_root()\n",
    "DATA_DIR = ROOT_DIR / \"data\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9b2102dd84f4bdc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:06.063825Z",
     "start_time": "2025-07-01T05:30:05.807408Z"
    }
   },
   "source": [
    "# matplotlib 의 한글 font 설정\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "FONTS_DATA_DIR = DATA_DIR / \"fonts\"\n",
    "\n",
    "\n",
    "def setup_korean_font():\n",
    "    font_path = FONTS_DATA_DIR / KOREAN_FONT_FILE\n",
    "    fm.fontManager.addfont(font_path)\n",
    "\n",
    "    # 폰트 설정\n",
    "    plt.rcParams[\"font.family\"] = KOREAN_FONT_FAMILY\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "\n",
    "setup_korean_font()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "bac8d04607dc6327",
   "metadata": {},
   "source": "# Baseline Code 분석하기"
  },
  {
   "cell_type": "code",
   "id": "135a7c6f3a7571cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:06.809867Z",
     "start_time": "2025-07-01T05:30:06.066645Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def fix_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "67b959220656913d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:06.840597Z",
     "start_time": "2025-07-01T05:30:06.817433Z"
    }
   },
   "source": [
    "SEED = 4321\n",
    "fix_random_seed(SEED)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "d3694e219dd515c7",
   "metadata": {},
   "source": "## Dataset 정의"
  },
  {
   "cell_type": "code",
   "id": "2375f8d8ca68e55f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:07.097167Z",
     "start_time": "2025-07-01T05:30:06.846592Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DocumentImageDataset(Dataset):\n",
    "    def __init__(self, csv_path: Path, image_dir: Path, transform=None):\n",
    "        self.image_metadata_df = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_metadata_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_name, target = self.image_metadata_df.iloc[idx]\n",
    "        img = np.array(Image.open(str(self.image_dir / image_name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        return img, target"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a60c1262fd46073c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:08.044822Z",
     "start_time": "2025-07-01T05:30:07.103367Z"
    }
   },
   "source": [
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "tmp_transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(32, 32),\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tmp_img_dataset = DocumentImageDataset(\n",
    "    csv_path=DATA_DIR / \"raw\" / \"train.csv\", image_dir=DATA_DIR / \"raw\" / \"train\", transform=tmp_transform\n",
    ")\n",
    "print(\"total image size of train:\", len(tmp_img_dataset))\n",
    "\n",
    "tmp_dataloader = DataLoader(\n",
    "    tmp_img_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "# 데이터셋이 제대로 동작하는지 확인\n",
    "for b_imgs, b_targets in tmp_dataloader:\n",
    "    print(\"Shape of imgs:\", b_imgs.shape, \"| Shape of targets:\", b_targets.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total image size of train: 1570\n",
      "Shape of imgs: torch.Size([4, 3, 32, 32]) | Shape of targets: torch.Size([4])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "e275a54c30d9c54d",
   "metadata": {},
   "source": "- 여러 플랫폼에서 실행해도 torch.device 를 사용할 수 있도록 함수 정의"
  },
  {
   "cell_type": "code",
   "id": "992274321c6b8667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:08.072979Z",
     "start_time": "2025-07-01T05:30:08.071191Z"
    }
   },
   "source": [
    "def get_device() -> torch.device:\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "477074fcb7d581d0",
   "metadata": {},
   "source": "## train 함수 정의"
  },
  {
   "cell_type": "code",
   "id": "5fe9b02602faba8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:09.075046Z",
     "start_time": "2025-07-01T05:30:08.082043Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_per_one_epoch(\n",
    "    loader: DataLoader, model: nn.Module, optimizer: optim.Optimizer, loss_fn: nn.Module, device: torch.device\n",
    "):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for images, targets in pbar:\n",
    "        model.zero_grad()\n",
    "\n",
    "        images_in_device = images.to(device)\n",
    "        targets_in_device = targets.to(device)\n",
    "\n",
    "        preds = model(images_in_device)\n",
    "\n",
    "        loss = loss_fn(preds, targets_in_device)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        predictions_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets_in_device.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = train_loss / len(loader)\n",
    "    train_accuracy = accuracy_score(targets_list, predictions_list)\n",
    "    train_f1 = f1_score(targets_list, predictions_list, average=\"macro\")\n",
    "    return {\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"train_f1\": train_f1,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "9027236c14957939",
   "metadata": {},
   "source": "## Hyper-parameters"
  },
  {
   "cell_type": "code",
   "id": "967ab6e3a4181174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:09.098638Z",
     "start_time": "2025-07-01T05:30:09.083802Z"
    }
   },
   "source": [
    "local_device = get_device()\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "MODEL_NAME = \"resnet34\"\n",
    "IMAGE_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "6428c6f0724cc2e3",
   "metadata": {},
   "source": "## Load Data"
  },
  {
   "cell_type": "code",
   "id": "af89435ce24d146b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:09.109639Z",
     "start_time": "2025-07-01T05:30:09.106296Z"
    }
   },
   "source": [
    "# train image 의 변환을 위한 transform\n",
    "train_transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# test image 의 변환을 위한 transform\n",
    "test_transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "e3b7504a008ec104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:09.124Z",
     "start_time": "2025-07-01T05:30:09.117730Z"
    }
   },
   "source": [
    "train_dataset = DocumentImageDataset(\n",
    "    csv_path=RAW_DIR / \"train.csv\", image_dir=RAW_DIR / \"train\", transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = DocumentImageDataset(\n",
    "    csv_path=RAW_DIR / \"sample_submission.csv\", image_dir=RAW_DIR / \"test\", transform=test_transform\n",
    ")\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1570, 3140)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "e35904c2e8770380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:09.138902Z",
     "start_time": "2025-07-01T05:30:09.137073Z"
    }
   },
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "2f4b89342ff097a7",
   "metadata": {},
   "source": "## Train Model"
  },
  {
   "cell_type": "code",
   "id": "b9bb09373d7176bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:11.665532Z",
     "start_time": "2025-07-01T05:30:09.148071Z"
    }
   },
   "source": [
    "import timm\n",
    "\n",
    "\n",
    "pretrained_model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=17).to(local_device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "adam_optimizer = optim.Adam(pretrained_model.parameters(), lr=LEARNING_RATE)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "5609f7bd5d3624f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:37.595771Z",
     "start_time": "2025-07-01T05:30:11.675464Z"
    }
   },
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    r = train_per_one_epoch(\n",
    "        loader=train_loader, model=pretrained_model, optimizer=adam_optimizer, loss_fn=criterion, device=local_device\n",
    "    )\n",
    "\n",
    "    for k, v in r.items():\n",
    "        print(\"    \", f\"{k}: {v}\")\n",
    "    print(\"    \", \"epoch:\", epoch + 1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1448: 100%|██████████| 25/25 [00:03<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 2.553156518936157\n",
      "     train_accuracy: 0.23312101910828026\n",
      "     train_f1: 0.1885272313025145\n",
      "     epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6273: 100%|██████████| 25/25 [00:02<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 1.8247415590286256\n",
      "     train_accuracy: 0.4694267515923567\n",
      "     train_f1: 0.4007415035881568\n",
      "     epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0917: 100%|██████████| 25/25 [00:02<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 1.415084147453308\n",
      "     train_accuracy: 0.5910828025477707\n",
      "     train_f1: 0.5165581199173994\n",
      "     epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3204: 100%|██████████| 25/25 [00:02<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 1.0024565529823304\n",
      "     train_accuracy: 0.6968152866242038\n",
      "     train_f1: 0.6360485189997257\n",
      "     epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5621: 100%|██████████| 25/25 [00:02<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 0.7155654644966125\n",
      "     train_accuracy: 0.7694267515923567\n",
      "     train_f1: 0.7307302347971265\n",
      "     epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8697: 100%|██████████| 25/25 [00:02<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 0.5203204691410065\n",
      "     train_accuracy: 0.8254777070063695\n",
      "     train_f1: 0.8047571936316199\n",
      "     epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4421: 100%|██████████| 25/25 [00:02<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 0.3899052917957306\n",
      "     train_accuracy: 0.867515923566879\n",
      "     train_f1: 0.8548551761490054\n",
      "     epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0818: 100%|██████████| 25/25 [00:02<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 0.28459398180246354\n",
      "     train_accuracy: 0.9127388535031847\n",
      "     train_f1: 0.9070205906431783\n",
      "     epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2334: 100%|██████████| 25/25 [00:02<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 0.22844529867172242\n",
      "     train_accuracy: 0.924203821656051\n",
      "     train_f1: 0.9181047873984138\n",
      "     epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4405: 100%|██████████| 25/25 [00:02<00:00, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     avg_train_loss: 0.22436793237924577\n",
      "     train_accuracy: 0.9312101910828026\n",
      "     train_f1: 0.9241498684192844\n",
      "     epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "861df811729062c5",
   "metadata": {},
   "source": "## Inference"
  },
  {
   "cell_type": "code",
   "id": "4afe464119111e14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:37.608376Z",
     "start_time": "2025-07-01T05:30:37.606237Z"
    }
   },
   "source": [
    "def inference(loader: DataLoader, model: nn.Module, device: torch.device):\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "    for images, _ in tqdm(loader):\n",
    "        images_in_device = images.to(device)\n",
    "        preds = model(images_in_device)\n",
    "        predictions_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "    return predictions_list"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "455fde7ffa2de892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:43.501835Z",
     "start_time": "2025-07-01T05:30:37.612099Z"
    }
   },
   "source": [
    "preds_list = inference(test_loader, pretrained_model, local_device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  8.49it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "f4c2a0e2b4973c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:43.519622Z",
     "start_time": "2025-07-01T05:30:43.515984Z"
    }
   },
   "source": [
    "result = test_dataset.image_metadata_df.copy()\n",
    "result[\"target\"] = preds_list"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "540611e34d5f8cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T05:30:43.534232Z",
     "start_time": "2025-07-01T05:30:43.529913Z"
    }
   },
   "source": [
    "result.to_csv(RAW_DIR / \"predictions.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
